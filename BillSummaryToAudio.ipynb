{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-ai-documentintelligence azure-cognitiveservices-speech openai python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import json\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
    "from openai import AzureOpenAI\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Read configurations and setup the sdk clients\n",
    "load_dotenv()\n",
    "openai_model = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "input_path = \"./input\"\n",
    "output_path = \"./output\"\n",
    "\n",
    "document_intelligence_key = os.getenv(\"DOCUMENT_INTELLIGENCE_KEY\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_speech_key = os.getenv(\"AZURE_SPEECH_KEY\")\n",
    "\n",
    "if not all([document_intelligence_key, azure_openai_key, azure_speech_key]):\n",
    "    raise ValueError(\"One or more Azure keys are not set in the environment variables.\")\n",
    "\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint = os.getenv(\"DOCUMENT_INTELLIGENCE_ENDPOINT\"), \n",
    "    credential = AzureKeyCredential(document_intelligence_key)\n",
    ")\n",
    "\n",
    "aoai_client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key = azure_openai_key,  \n",
    "  api_version = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    ")\n",
    "\n",
    "speech_config = speechsdk.SpeechConfig(\n",
    "  subscription=azure_speech_key,\n",
    "  region=os.getenv(\"AZURE_SPEECH_REGION\"),\n",
    ")\n",
    "speech_config.speech_synthesis_voice_name='en-US-AvaMultilingualNeural'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your prompts\n",
    "\n",
    "system_prompt_template = \"\"\"You are an AI assistant that is helping to extract text from a document and then turn that text back into speech.\n",
    "The document has been processed with the document intelligence service and you will be provided with the JSON output from that analysis.\n",
    "- Find and extract text exactly as supplied without altering.\n",
    "- Do not be creative.\n",
    "- Your only role is to extract the desired information.\n",
    "- Do not extract more than is requested.\n",
    "- Use minimal markdown formatting so each key and its corresponding value can be spoken correctly.\n",
    "- Don't bold anything.\n",
    "- If you see a single 'o' character at the beginning of a line, like a bullet mark, replace it with a single dash, '-', so it is compatible with markdown.\"\"\"\n",
    "\n",
    "user_prompt_template = \"\"\"\"Please extract the Bill Number, Sponsor, and Bill Summary from the following json.  \n",
    "Make sure the Bill Summary includes all content in the Bill Summary section, up to but not including the Current Law section.\n",
    "Document JSON:\n",
    "{content}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract content from a local document\n",
    "def extract_content(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\", body=f, content_type=\"application/pdf\"\n",
    "        )\n",
    "\n",
    "    result: AnalyzeResult = poller.result()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Define function to call Azure OpenAI\n",
    "def extract_fields_with_openai(system_prompt, user_prompt):\n",
    "    response = aoai_client.chat.completions.create(\n",
    "        model = os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "        messages = [{\"role\":\"system\",\"content\":system_prompt},{\"role\":\"user\",\"content\":user_prompt}],\n",
    "    )\n",
    "\n",
    "    generated_response = response.choices[0].message.content.strip()\n",
    "    return generated_response\n",
    "\n",
    "# Define a function to convert text to speech\n",
    "def text_to_speech(text, output_file):\n",
    "    # Synthesize to audio data stream\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(filename=output_file)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "    print(f\"Audio content written to file {output_file}\")\n",
    "\n",
    "\n",
    "def clean_analyze_result(analyze_result):\n",
    "    def remove_elements(element, keys_to_remove):\n",
    "        if isinstance(element, dict):\n",
    "            for key in keys_to_remove:\n",
    "                if key in element:\n",
    "                    del element[key]\n",
    "            for key, value in element.items():\n",
    "                remove_elements(value, keys_to_remove)\n",
    "        elif isinstance(element, list):\n",
    "            for item in element:\n",
    "                remove_elements(item, keys_to_remove)\n",
    "\n",
    "    analyze_result_dict = analyze_result.as_dict()\n",
    "    \n",
    "    # Remove boundingRegions and words elements recursively\n",
    "    keys_to_remove = ['boundingRegions', 'words', 'polygon']\n",
    "    remove_elements(analyze_result_dict, keys_to_remove)\n",
    "    \n",
    "    return analyze_result_dict\n",
    "\n",
    "# Define a function to save extracted data to a file\n",
    "def save_data(data, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all documents in the input directory\n",
    "\n",
    "# Clear the output directory\n",
    "for file in os.listdir(output_path):\n",
    "    file_path = os.path.join(output_path, file)\n",
    "    os.remove(file_path)\n",
    "\n",
    "for filename in os.listdir(input_path):\n",
    "    file_path = os.path.join(input_path, filename)\n",
    "    output_filename = os.path.join(output_path, f\"{os.path.splitext(filename)[0]}\")\n",
    "\n",
    "    raw_json_path = output_filename + \".raw.json\"\n",
    "    clean_json_path = output_filename + \".clean.json\"\n",
    "    txt_path = output_filename + \".txt\"\n",
    "    wav_path = output_filename + \".wav\"\n",
    "\n",
    "    # Get the content of the document. Result is in json format.\n",
    "    docContent = extract_content(file_path)\n",
    "    save_data(json.dumps(docContent.as_dict()), raw_json_path)\n",
    "\n",
    "    # Clean the json content to reduce it's (token) size\n",
    "    cleanDocContent = clean_analyze_result(docContent)\n",
    "    save_data(json.dumps(cleanDocContent), clean_json_path)\n",
    "\n",
    "    # Extract the content from the json file using genai\n",
    "    prompt = user_prompt_template.format(content=cleanDocContent)\n",
    "    extracted_data = extract_fields_with_openai(system_prompt_template, prompt)\n",
    "    save_data(extracted_data, txt_path)\n",
    "\n",
    "    # Convert the extracted data to speech\n",
    "    text_to_speech(extracted_data, wav_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process all documents in the input directory\n",
    "\n",
    "# # Comment out the empty folder lines\n",
    "# # for file in os.listdir(output_path):\n",
    "# #     file_path = os.path.join(output_path, file)\n",
    "# #     os.remove(file_path)\n",
    "\n",
    "# for filename in os.listdir(input_path):\n",
    "#     file_path = os.path.join(input_path, filename)\n",
    "#     output_filename = os.path.join(output_path, f\"{os.path.splitext(filename)[0]}\")\n",
    "\n",
    "#     raw_json_path = output_filename + \".raw.json\"\n",
    "#     clean_json_path = output_filename + \".clean.json\"\n",
    "#     txt_path = output_filename + \".txt\"\n",
    "#     wav_path = output_filename + \".wav\"\n",
    "\n",
    "\n",
    "#     with open(clean_json_path, 'r') as f:\n",
    "#         cleanDocContent = json.load(f)\n",
    "\n",
    "#     # Extract the content from the json file using genai\n",
    "#     prompt = user_prompt_template.format(content=cleanDocContent)\n",
    "#     extracted_data = extract_fields_with_openai(system_prompt_template, prompt)\n",
    "#     save_data(extracted_data, txt_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
